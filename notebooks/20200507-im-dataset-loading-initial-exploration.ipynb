{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data stages\n",
    "01_raw <- Aligned and labeled TPA+RGB. Not handled by the project. \n",
    "02_intermediate <- Aligned and labeled TPA+RGB that was cropped. Crop parameters can vary. Not handled by the project.\n",
    "03_procesed <- Intermediate cropped data after normalization. Input to the models.\n",
    "\n",
    "# Processed data\n",
    "I'm using dataset_npz_f100_fs0 consisting of three positive samples and one negative sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 positive samples:\n",
      "['/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1547_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1552_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1553_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1556_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1554_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1525_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1527_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1521_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1523_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1522_.npz']\n",
      "\n",
      "18 negative samples:\n",
      "['/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch7_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch5_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch8_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch3_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch4_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch2_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch1_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch6_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch0_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch4_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch3_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch1_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch6_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch8_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch0_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch5_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch2_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch7_20200508_1529_.npz']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "DATASET_NAME = \"/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0\"\n",
    "pos_fp_list = glob.glob(os.path.join(\"..\", \"data\", \"02_intermediate\", DATASET_NAME, \"*\", \"1\", \"*.npz\"))\n",
    "neg_fp_list = glob.glob(os.path.join(\"..\", \"data\", \"02_intermediate\", DATASET_NAME, \"*\", \"0\", \"*.npz\"))\n",
    "\n",
    "print(\"{} positive samples:\".format(len(pos_fp_list)))\n",
    "print(pos_fp_list)\n",
    "print()\n",
    "print(\"{} negative samples:\".format(len(neg_fp_list)))\n",
    "print(neg_fp_list)\n",
    "del(pos_fp_list, neg_fp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In form of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_neg_fp_lists(dataset_name):\n",
    "    pos_fp_list = glob.glob(os.path.join(\"..\", \"data\", \"02_intermediate\", dataset_name, \"*\", \"1\", \"*.npz\"))\n",
    "    neg_fp_list = glob.glob(os.path.join(\"..\", \"data\", \"02_intermediate\", dataset_name, \"*\", \"0\", \"*.npz\"))\n",
    "    return pos_fp_list, neg_fp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all positive and negative samples (in lists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 positive samples:\n",
      "['/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1547_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1552_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1553_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1556_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1554_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1525_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1527_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1521_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1523_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1522_.npz']\n",
      "\n",
      "18 negative samples:\n",
      "['/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch7_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch5_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch8_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch3_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch4_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch2_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch1_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch6_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch0_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch4_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch3_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch1_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch6_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch8_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch0_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch5_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch2_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch7_20200508_1529_.npz']\n"
     ]
    }
   ],
   "source": [
    "pos_fp_list, neg_fp_list = get_pos_neg_fp_lists(DATASET_NAME)\n",
    "print(\"{} positive samples:\".format(len(pos_fp_list)))\n",
    "print(pos_fp_list)\n",
    "print()\n",
    "print(\"{} negative samples:\".format(len(neg_fp_list)))\n",
    "print(neg_fp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to read TPA and RGB samples. Let's read the keys in NumPy archives that contain our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one_hot', 'frames', 'frame_shift', 'tpa_avg_timestamps', 'tpa_rgb_avg_timestamps', 'pad_first', 'pad_last', 'repeating_frames', 'array_ID121', 'array_ID122', 'array_ID123', 'timestamps_ID121', 'timestamps_ID122', 'timestamps_ID123', 'array_IDRGB', 'timestamps_IDRGB']\n"
     ]
    }
   ],
   "source": [
    "tmp_f = pos_fp_list[0]\n",
    "print(list(np.load(tmp_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample in the project will have the following keys:\n",
    "\n",
    "* `'one_hot'` < pos/neg one-hot-encoded label.\n",
    "* `'frames'` < as in array\\[frame_shift:frames+frame_shift\\] that was used to extract patches.\n",
    "* `'frame_shift'` < as in array\\[frame_shift:frames+frame_shift\\] that was used to extract patches.\n",
    "* `'tpa_avg_timestamps'` < TPA timestamps averaged (per timestep).\n",
    "* `'tpa_rgb_avg_timestamps'` < TPA+RGB timestamps averaged (per timestep).\n",
    "* `'pad_first'` < Number of frames repeated at the beginning of the sequence (still frames).\n",
    "* `'pad_last'` < Number of frames repeated at the end of the sequence (still frames).\n",
    "* `'repeating_frames'` < True if repeating frames enabled.\n",
    "* `'array_ID121'` < TPA sequence from view with ID 121.\n",
    "* `'array_ID122'` < As above.\n",
    "* `'array_ID123'` < As above.\n",
    "* `'timestamps_ID121'` < Timestamps of TPA sequence from view with ID 121.\n",
    "* `'timestamps_ID122'` < As above.\n",
    "* `'timestamps_ID123'` < As above.\n",
    "* `'array_IDRGB'` < RGB sequence.\n",
    "* `'timestamps_IDRGB'` < Timestamps of RGB sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load in some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x7fca04067908>\n"
     ]
    }
   ],
   "source": [
    "pos_samples = [np.load(f) for f in pos_fp_list]\n",
    "neg_samples = [np.load(f) for f in neg_fp_list]\n",
    "print(pos_samples[0])\n",
    "del(pos_samples, neg_samples, pos_fp_list, neg_fp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_from_fp_list(fp_list):\n",
    "    return [np.load(f) for f in fp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x7fca04067860>\n"
     ]
    }
   ],
   "source": [
    "pos_fp_list, neg_fp_list = get_pos_neg_fp_lists(DATASET_NAME)\n",
    "pos_samples = samples_from_fp_list(pos_fp_list)\n",
    "neg_samples = samples_from_fp_list(neg_fp_list)\n",
    "print(pos_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32, 32) float16\n",
      "(100, 32, 32) float16\n",
      "(100, 32, 32) float16\n",
      "(100, 480, 480, 3) uint8\n"
     ]
    }
   ],
   "source": [
    "sample = pos_samples[0]\n",
    "tpa1 = sample['array_ID121']\n",
    "print(tpa1.shape, tpa1.dtype)\n",
    "tpa2 = sample['array_ID122']\n",
    "print(tpa2.shape, tpa2.dtype)\n",
    "tpa3 = sample['array_ID123']\n",
    "print(tpa3.shape, tpa3.dtype)\n",
    "rgb = sample['array_IDRGB']\n",
    "print(rgb.shape, rgb.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPA arrays in the intermediate state need expanding dimensions by one so that the last dimension is a channel instead of spatial dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32, 32, 1) float16\n",
      "(100, 32, 32, 1) float16\n",
      "(100, 32, 32, 1) float16\n",
      "(100, 480, 480, 3) uint8\n"
     ]
    }
   ],
   "source": [
    "sample = pos_samples[0]\n",
    "tpa1 = np.expand_dims(sample['array_ID121'],axis=-1)\n",
    "print(tpa1.shape, tpa1.dtype)\n",
    "tpa2 = np.expand_dims(sample['array_ID122'],axis=-1)\n",
    "print(tpa2.shape, tpa2.dtype)\n",
    "tpa3 = np.expand_dims(sample['array_ID123'],axis=-1)\n",
    "print(tpa3.shape, tpa3.dtype)\n",
    "rgb = sample['array_IDRGB']\n",
    "print(rgb.shape, rgb.dtype)\n",
    "del(tpa1, tpa2, tpa3, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to convert data to appropriate float-type as well as normalize it. Now, we will also handle reading the label and timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tpa123_from_npz(npz_sample, dtype=np.float32):\n",
    "    ids = ('121', '122', '123')\n",
    "    return [np.expand_dims(npz_sample['array_ID{}'.format(id)],axis=-1).astype(dtype) for id in ids]\n",
    "\n",
    "def read_rgb_from_npz(npz_sample):\n",
    "    return npz_sample['array_IDRGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label  [0 1]\n",
      "(100, 32, 32, 1) float32\n",
      "(100, 32, 32, 1) float32\n",
      "(100, 32, 32, 1) float32\n",
      "(100, 480, 480, 3) uint8\n",
      "100 averaged TPA timestamps\n",
      "100 averaged TPA+RGB timestamps\n"
     ]
    }
   ],
   "source": [
    "sample = pos_samples[0]\n",
    "print('Label ',sample['one_hot'])\n",
    "tpa1, tpa2, tpa3, rgb = *read_tpa123_from_npz(sample), read_rgb_from_npz(sample)\n",
    "print(tpa1.shape, tpa1.dtype)\n",
    "print(tpa2.shape, tpa2.dtype)\n",
    "print(tpa3.shape, tpa3.dtype)\n",
    "print(rgb.shape, rgb.dtype)\n",
    "print('{} averaged TPA timestamps'.format(len(sample['tpa_avg_timestamps'])))\n",
    "print('{} averaged TPA+RGB timestamps'.format(len(sample['tpa_rgb_avg_timestamps'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "Normalize as in [20200507-im-normalization-tanh.ipynb](20200507-im-normalization-tanh.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1e-1\n",
    "b = 30\n",
    "scale = 50\n",
    "\n",
    "def normalize_TPA(array, a, b, scale=1):\n",
    "    return scale*np.tanh(a*(array-b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g.: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw\n",
      "[18 20 22 24 26 28 30 32 34]\n",
      "Normalized\n",
      "[-41.68 -38.08 -33.2  -26.85 -19.    -9.87   0.     9.87  19.  ]\n"
     ]
    }
   ],
   "source": [
    "tmp = np.arange(18, 36, 2)\n",
    "print('Raw')\n",
    "print(tmp)\n",
    "print('Normalized')\n",
    "tmp = normalize_TPA(tmp, a, b, scale)\n",
    "print(np.round(tmp, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "29.77 >> -1.17\n",
      "29.77 >> -1.15\n",
      "29.8 >> -1.01\n",
      "Deviation:\n",
      "0.19 >> 0.96\n",
      "0.16 >> 0.81\n",
      "0.18 >> 0.89\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\")\n",
    "print(np.round(tpa1.mean(), 2), '>>', np.round(normalize_TPA(tpa1, a, b, scale).mean(), 2))\n",
    "print(np.round(tpa2.mean(), 2), '>>', np.round(normalize_TPA(tpa2, a, b, scale).mean(), 2))\n",
    "print(np.round(tpa3.mean(), 2), '>>', np.round(normalize_TPA(tpa3, a, b, scale).mean(), 2))\n",
    "print(\"Deviation:\")\n",
    "print(np.round(tpa1.std(), 2), '>>', np.round(normalize_TPA(tpa1, a, b, scale).std(), 2))\n",
    "print(np.round(tpa2.std(), 2), '>>', np.round(normalize_TPA(tpa2, a, b, scale).std(), 2))\n",
    "print(np.round(tpa3.std(), 2), '>>', np.round(normalize_TPA(tpa3, a, b, scale).std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It will be probably safer to perform standarization. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "29.77 >> 0.02\n",
      "29.77 >> 0.04\n",
      "29.8 >> 0.2\n",
      "Deviation:\n",
      "0.19 >> 1.05\n",
      "0.16 >> 0.89\n",
      "0.18 >> 0.97\n"
     ]
    }
   ],
   "source": [
    "def get_TPA_mean_and_std(sample_list):\n",
    "    data = read_tpa123_from_npz(sample_list[0], dtype=np.float16)[0][0][0][0][0]\n",
    "    for sample in sample_list:\n",
    "        tpa1, tpa2, tpa3 = read_tpa123_from_npz(sample, dtype=np.float16)\n",
    "        tpas = np.concatenate([tpa1, tpa2, tpa3]).flatten()\n",
    "        data = np.append(data, tpas)\n",
    "    data = data.astype(np.float32)\n",
    "    return data.mean(), data.std()\n",
    "\n",
    "def standarize_TPA(array, mean, std):\n",
    "    return (array - mean) / std\n",
    "\n",
    "TPA_mean, TPA_std = get_TPA_mean_and_std(pos_samples + neg_samples)\n",
    "\n",
    "print(\"Mean:\")\n",
    "print(np.round(tpa1.mean(), 2), '>>', np.round(standarize_TPA(tpa1, TPA_mean, TPA_std).mean(), 2))\n",
    "print(np.round(tpa2.mean(), 2), '>>', np.round(standarize_TPA(tpa2, TPA_mean, TPA_std).mean(), 2))\n",
    "print(np.round(tpa3.mean(), 2), '>>', np.round(standarize_TPA(tpa3, TPA_mean, TPA_std).mean(), 2))\n",
    "print(\"Deviation:\")\n",
    "print(np.round(tpa1.std(), 2), '>>', np.round(standarize_TPA(tpa1, TPA_mean, TPA_std).std(), 2))\n",
    "print(np.round(tpa2.std(), 2), '>>', np.round(standarize_TPA(tpa2, TPA_mean, TPA_std).std(), 2))\n",
    "print(np.round(tpa3.std(), 2), '>>', np.round(standarize_TPA(tpa3, TPA_mean, TPA_std).std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to perform normalization on RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_RGB(rgb_sequence):\n",
    "    return (rgb_sequence - rgb_sequence.mean()) / rgb_sequence.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "125.72 >> 0.0\n",
      "Deviation:\n",
      "66.66 >> 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\")\n",
    "print(np.round(rgb.mean(), 2), '>>', np.round(standarize_RGB(rgb).mean(), 2))\n",
    "print(\"Deviation:\")\n",
    "print(np.round(rgb.std(), 2), '>>', np.round(standarize_RGB(rgb).std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the number of computations performed we probably want to perform these on RGB sequence resized to desired input shape (we assume that it's cropped to center when converting raw >> intermediate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to move from 02_intermediate to 03_processed that will be ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_fp_list, neg_fp_list = get_pos_neg_fp_lists(DATASET_NAME)\n",
    "pos_samples = samples_from_fp_list(pos_fp_list)\n",
    "neg_samples = samples_from_fp_list(neg_fp_list)\n",
    "\n",
    "for sample in pos_samples + neg_samples:\n",
    "    tpa1, tpa2, tpa3 = read_tpa123_from_npz(sample)\n",
    "    rgb = read_rgb_from_npz(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-cb85a42f42bf>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-cb85a42f42bf>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    def read_rgb_from_npz(npz_sample, !*):\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def get_pos_neg_fp_lists(dataset_name):\n",
    "    pos_fp_list = glob.glob(os.path.join(\"..\", \"data\", \"02_intermediate\", dataset_name, \"*\", \"1\", \"*.npz\"))\n",
    "    neg_fp_list = glob.glob(os.path.join(\"..\", \"data\", \"02_intermediate\", dataset_name, \"*\", \"0\", \"*.npz\"))\n",
    "    return pos_fp_list, neg_fp_list\n",
    "\n",
    "def samples_from_fp_list(fp_list):\n",
    "    return [np.load(f) for f in fp_list]\n",
    "\n",
    "def read_tpa123_from_npz(npz_sample, dtype=np.float32):\n",
    "    ids = ('121', '122', '123')\n",
    "    return [np.expand_dims(npz_sample['array_ID{}'.format(id)],axis=-1).astype(dtype) for id in ids]\n",
    "\n",
    "def read_rgb_from_npz(npz_sample, !*):\n",
    "    return npz_sample['array_IDRGB']\n",
    "\n",
    "a = 1e-1\n",
    "b = 30\n",
    "\n",
    "def normalize_TPA(array, a, b, scale=1):\n",
    "    return scale*np.tanh(a*(array-b))\n",
    "\n",
    "def standarize_RGB(rgb_sequence):\n",
    "    return (rgb_sequence - rgb_sequence.mean()) / rgb_sequence.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
