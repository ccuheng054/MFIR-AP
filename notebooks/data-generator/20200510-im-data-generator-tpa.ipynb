{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3\n",
      "1 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "WORKING_DIR = os.path.join(\"..\", \"..\")\n",
    "PROCESSED_PATH = os.path.join(WORKING_DIR, \"data\", \"03_processed\")\n",
    "DATASET_PATH = glob.glob(os.path.join(PROCESSED_PATH,\"*\"))[0]\n",
    "\n",
    "class Train_Validation_Generators:\n",
    "    def __init__(self, dataset_path, view_IDs, train_size, batch_size=32, shuffle=True, RGB=False):\n",
    "        self.devel_path = os.path.join(dataset_path, \"development\")    \n",
    "        self.train_size = train_size\n",
    "        self.view_IDs = view_IDs.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.RGB = RGB\n",
    "        self.shuffle = shuffle\n",
    "        if train_size > 1:\n",
    "            train_size = 1\n",
    "        if (train_size == -1):\n",
    "            train_size = 1.0\n",
    "        self.validation_size = 1-train_size\n",
    "        def _read_samples_in_subfolder(zero_or_one):\n",
    "            fp_list = glob.glob(os.path.join(self.devel_path, str(zero_or_one), \"*.npz\"))\n",
    "            return [np.load(f) for f in fp_list]\n",
    "        pos_samples = _read_samples_in_subfolder(1)\n",
    "        neg_samples = _read_samples_in_subfolder(0)\n",
    "        random.shuffle(pos_samples)\n",
    "        random.shuffle(neg_samples)\n",
    "        m = len(pos_samples) if len(pos_samples) < len(neg_samples) else len(neg_samples)\n",
    "        split_pt = int(self.train_size * m)\n",
    "        self.train_pos_samples, self.train_neg_samples = pos_samples[:split_pt], neg_samples[:split_pt]\n",
    "        self.valid_pos_samples, self.valid_neg_samples = pos_samples[split_pt:], neg_samples[split_pt:]\n",
    "    \n",
    "    def get_train(self):\n",
    "        return Data_generator(self.train_pos_samples, self.train_neg_samples, view_IDs = self.view_IDs, batch_size = self.batch_size, shuffle = self.shuffle, RGB = self.RGB)\n",
    "    \n",
    "    def get_valid(self):\n",
    "        return Data_generator(self.valid_pos_samples, self.valid_neg_samples, view_IDs = self.view_IDs, batch_size = self.batch_size, shuffle = self.shuffle, RGB = self.RGB)\n",
    "        \n",
    "class Data_generator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, pos_samples, neg_samples, view_IDs, batch_size=32, shuffle=True, RGB=False):\n",
    "        self.pos_samples = pos_samples.copy()\n",
    "        self.neg_samples = neg_samples.copy()\n",
    "        self.view_IDs = view_IDs.copy()\n",
    "        self.RGB = RGB\n",
    "        self.keys = ['array_ID{}'.format(id) for id in self.view_IDs]\n",
    "        if self.RGB:\n",
    "            self.keys += ['array_IDRGB']\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.pos_in_batch_n = self.batch_size // 2\n",
    "        self.neg_in_batch_n = self.pos_in_batch_n\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        m = len(self.pos_samples) if len(self.pos_samples) < len(self.neg_samples) else len(self.neg_samples)\n",
    "        return int(np.floor(m) / self.batch_size)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indices = list(range(index * self.pos_in_batch_n, (index + 1) * self.pos_in_batch_n))\n",
    "        return self._load_data(indices)\n",
    "    \n",
    "    def _load_data(self, indices):\n",
    "        data =  [[] for i in range(len(self.keys))]\n",
    "        Y = []\n",
    "        for idx in indices:\n",
    "            samples = [self.pos_samples[idx], self.neg_samples[idx]]\n",
    "            for sample in samples:\n",
    "                [data[i].append(sample[id]) for i, id in enumerate(self.keys)]\n",
    "                Y.append(sample['one_hot'])\n",
    "        # Y [B,2] > [B, F, 2]\n",
    "        Y = np.tile(np.expand_dims(np.array(Y), axis=1), [1, sample['frames'], 1])\n",
    "        x = [np.array(view) for view in data]\n",
    "        assert all([len(view) == len(Y) for view in x])\n",
    "        return x, Y\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle == True:\n",
    "            random.shuffle(self.pos_samples)\n",
    "            random.shuffle(self.neg_samples)\n",
    "          \n",
    "RGB = 0\n",
    "generators = Train_Validation_Generators(dataset_path=DATASET_PATH, view_IDs=[\"121\", \"122\", \"123\"], train_size=1, batch_size=4, RGB=RGB)\n",
    "train_generator = generators.get_train()\n",
    "valid_generator = generators.get_valid()\n",
    "x, y = train_generator[0]\n",
    "print(RGB, len(x))\n",
    "\n",
    "RGB = 1\n",
    "generators = Train_Validation_Generators(dataset_path=DATASET_PATH, view_IDs=[\"121\", \"122\", \"123\"], train_size=1, batch_size=4, RGB=RGB)\n",
    "train_generator = generators.get_train()\n",
    "valid_generator = generators.get_valid()\n",
    "x, y = train_generator[0]\n",
    "print(RGB, len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load('data/' + ID + '.npy')\n",
    "\n",
    "            # Store class\n",
    "            y[i] = self.labels[ID]\n",
    "\n",
    "        return X, keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
