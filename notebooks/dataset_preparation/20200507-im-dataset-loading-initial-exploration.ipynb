{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data stages\n",
    "01_raw <- Aligned and labeled TPA+RGB. Not handled by the project. \n",
    "02_intermediate <- Aligned and labeled TPA+RGB that was cropped. Crop parameters can vary. Not handled by the project.\n",
    "03_procesed <- Intermediate cropped data after normalization. Input to the models.\n",
    "\n",
    "# Processed data\n",
    "I'm using dataset_npz_f100_fs0 consisting of three positive samples and one negative sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 positive samples:\n",
      "['/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1547_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1552_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1553_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1556_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1554_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1525_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1527_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1521_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1523_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1522_.npz']\n",
      "\n",
      "18 negative samples:\n",
      "['/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch7_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch5_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch8_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch3_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch4_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch2_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch1_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch6_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch0_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch4_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch3_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch1_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch6_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch8_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch0_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch5_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch2_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch7_20200508_1529_.npz']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "VERBOSE = True\n",
    "\n",
    "DEST = os.path.join(\"..\", \"..\", \"data\", \"03_processed\")\n",
    "DATASET_NAME = \"/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0\"\n",
    "pos_fp_list = glob.glob(os.path.join(\"..\", \"..\", \"data\", \"02_intermediate\", DATASET_NAME, \"*\", \"1\", \"*.npz\"))\n",
    "neg_fp_list = glob.glob(os.path.join(\"..\", \"..\",  \"data\", \"02_intermediate\", DATASET_NAME, \"*\", \"0\", \"*.npz\"))\n",
    "\n",
    "print(\"{} positive samples:\".format(len(pos_fp_list)))\n",
    "print(pos_fp_list)\n",
    "print()\n",
    "print(\"{} negative samples:\".format(len(neg_fp_list)))\n",
    "print(neg_fp_list)\n",
    "del(pos_fp_list, neg_fp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In form of the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_neg_fp_lists(dataset_name):\n",
    "    pos_fp_list = glob.glob(os.path.join(\"..\", \"..\",  \"data\", \"02_intermediate\", dataset_name, \"*\", \"1\", \"*.npz\"))\n",
    "    neg_fp_list = glob.glob(os.path.join(\"..\",  \"..\", \"data\", \"02_intermediate\", dataset_name, \"*\", \"0\", \"*.npz\"))\n",
    "    return pos_fp_list, neg_fp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all positive and negative samples (in lists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 positive samples:\n",
      "['/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1547_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1552_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1553_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1556_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1554_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1525_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1527_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1521_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1523_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1522_.npz']\n",
      "\n",
      "18 negative samples:\n",
      "['/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch7_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch5_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch8_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch3_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch4_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch2_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch1_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch6_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch0_20200508_1557_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch4_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch3_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch1_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch6_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch8_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch0_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch5_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch2_20200508_1529_.npz', '/media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch7_20200508_1529_.npz']\n"
     ]
    }
   ],
   "source": [
    "pos_fp_list, neg_fp_list = get_pos_neg_fp_lists(DATASET_NAME)\n",
    "print(\"{} positive samples:\".format(len(pos_fp_list)))\n",
    "print(pos_fp_list)\n",
    "print()\n",
    "print(\"{} negative samples:\".format(len(neg_fp_list)))\n",
    "print(neg_fp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to read TPA and RGB samples. Let's read the keys in NumPy archives that contain our samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one_hot', 'frames', 'frame_shift', 'tpa_avg_timestamps', 'tpa_rgb_avg_timestamps', 'pad_first', 'pad_last', 'repeating_frames', 'array_ID121', 'array_ID122', 'array_ID123', 'timestamps_ID121', 'timestamps_ID122', 'timestamps_ID123', 'array_IDRGB', 'timestamps_IDRGB']\n"
     ]
    }
   ],
   "source": [
    "tmp_f = pos_fp_list[0]\n",
    "print(list(np.load(tmp_f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample in the project will have the following keys:\n",
    "\n",
    "* `'one_hot'` < pos/neg one-hot-encoded label.\n",
    "* `'frames'` < as in array\\[frame_shift:frames+frame_shift\\] that was used to extract patches.\n",
    "* `'frame_shift'` < as in array\\[frame_shift:frames+frame_shift\\] that was used to extract patches.\n",
    "* `'tpa_avg_timestamps'` < TPA timestamps averaged (per timestep).\n",
    "* `'tpa_rgb_avg_timestamps'` < TPA+RGB timestamps averaged (per timestep).\n",
    "* `'pad_first'` < Number of frames repeated at the beginning of the sequence (still frames).\n",
    "* `'pad_last'` < Number of frames repeated at the end of the sequence (still frames).\n",
    "* `'repeating_frames'` < True if repeating frames enabled.\n",
    "* `'array_ID121'` < TPA sequence from view with ID 121.\n",
    "* `'array_ID122'` < As above.\n",
    "* `'array_ID123'` < As above.\n",
    "* `'timestamps_ID121'` < Timestamps of TPA sequence from view with ID 121.\n",
    "* `'timestamps_ID122'` < As above.\n",
    "* `'timestamps_ID123'` < As above.\n",
    "* `'array_IDRGB'` < RGB sequence.\n",
    "* `'timestamps_IDRGB'` < Timestamps of RGB sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load in some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x7f04cae1b898>\n"
     ]
    }
   ],
   "source": [
    "pos_samples = [np.load(f) for f in pos_fp_list]\n",
    "neg_samples = [np.load(f) for f in neg_fp_list]\n",
    "print(pos_samples[0])\n",
    "del(pos_samples, neg_samples, pos_fp_list, neg_fp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_from_fp_list(fp_list):\n",
    "    return [np.load(f) for f in fp_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<numpy.lib.npyio.NpzFile object at 0x7f04cae06588>\n"
     ]
    }
   ],
   "source": [
    "pos_fp_list, neg_fp_list = get_pos_neg_fp_lists(DATASET_NAME)\n",
    "pos_samples = samples_from_fp_list(pos_fp_list)\n",
    "neg_samples = samples_from_fp_list(neg_fp_list)\n",
    "print(pos_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32, 32) float16\n",
      "(100, 32, 32) float16\n",
      "(100, 32, 32) float16\n",
      "(100, 299, 299, 3) uint8\n"
     ]
    }
   ],
   "source": [
    "sample = pos_samples[0]\n",
    "tpa1 = sample['array_ID121']\n",
    "print(tpa1.shape, tpa1.dtype)\n",
    "tpa2 = sample['array_ID122']\n",
    "print(tpa2.shape, tpa2.dtype)\n",
    "tpa3 = sample['array_ID123']\n",
    "print(tpa3.shape, tpa3.dtype)\n",
    "rgb = sample['array_IDRGB']\n",
    "print(rgb.shape, rgb.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPA arrays in the intermediate state need expanding dimensions by one so that the last dimension is a channel instead of spatial dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32, 32, 1) float16\n",
      "(100, 32, 32, 1) float16\n",
      "(100, 32, 32, 1) float16\n",
      "(100, 299, 299, 3) uint8\n"
     ]
    }
   ],
   "source": [
    "sample = pos_samples[0]\n",
    "tpa1 = np.expand_dims(sample['array_ID121'],axis=-1)\n",
    "print(tpa1.shape, tpa1.dtype)\n",
    "tpa2 = np.expand_dims(sample['array_ID122'],axis=-1)\n",
    "print(tpa2.shape, tpa2.dtype)\n",
    "tpa3 = np.expand_dims(sample['array_ID123'],axis=-1)\n",
    "print(tpa3.shape, tpa3.dtype)\n",
    "rgb = sample['array_IDRGB']\n",
    "print(rgb.shape, rgb.dtype)\n",
    "del(tpa1, tpa2, tpa3, rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to convert data to appropriate float-type as well as normalize it. Now, we will also handle reading the label and timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tpa123_from_npz(npz_sample, dtype=np.float32):\n",
    "    ids = ('121', '122', '123')\n",
    "    return [np.expand_dims(npz_sample['array_ID{}'.format(id)],axis=-1).astype(dtype) for id in ids]\n",
    "\n",
    "def read_rgb_from_npz(npz_sample):\n",
    "    return npz_sample['array_IDRGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label  [0 1]\n",
      "(100, 32, 32, 1) float32\n",
      "(100, 32, 32, 1) float32\n",
      "(100, 32, 32, 1) float32\n",
      "(100, 299, 299, 3) uint8\n",
      "100 averaged TPA timestamps\n",
      "100 averaged TPA+RGB timestamps\n"
     ]
    }
   ],
   "source": [
    "sample = pos_samples[0]\n",
    "print('Label ',sample['one_hot'])\n",
    "tpa1, tpa2, tpa3, rgb = *read_tpa123_from_npz(sample), read_rgb_from_npz(sample)\n",
    "print(tpa1.shape, tpa1.dtype)\n",
    "print(tpa2.shape, tpa2.dtype)\n",
    "print(tpa3.shape, tpa3.dtype)\n",
    "print(rgb.shape, rgb.dtype)\n",
    "print('{} averaged TPA timestamps'.format(len(sample['tpa_avg_timestamps'])))\n",
    "print('{} averaged TPA+RGB timestamps'.format(len(sample['tpa_rgb_avg_timestamps'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization\n",
    "Normalize as in [20200507-im-normalization-tanh.ipynb](20200507-im-normalization-tanh.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1e-1\n",
    "b = 30\n",
    "scale = 50\n",
    "\n",
    "def normalize_TPA(array, a, b, scale=1):\n",
    "    return scale*np.tanh(a*(array-b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g.: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw\n",
      "[18 20 22 24 26 28 30 32 34]\n",
      "Normalized\n",
      "[-41.68 -38.08 -33.2  -26.85 -19.    -9.87   0.     9.87  19.  ]\n"
     ]
    }
   ],
   "source": [
    "tmp = np.arange(18, 36, 2)\n",
    "print('Raw')\n",
    "print(tmp)\n",
    "print('Normalized')\n",
    "tmp = normalize_TPA(tmp, a, b, scale)\n",
    "print(np.round(tmp, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "29.77 >> -1.17\n",
      "29.77 >> -1.15\n",
      "29.8 >> -1.01\n",
      "Deviation:\n",
      "0.19 >> 0.96\n",
      "0.16 >> 0.81\n",
      "0.18 >> 0.89\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\")\n",
    "print(np.round(tpa1.mean(), 2), '>>', np.round(normalize_TPA(tpa1, a, b, scale).mean(), 2))\n",
    "print(np.round(tpa2.mean(), 2), '>>', np.round(normalize_TPA(tpa2, a, b, scale).mean(), 2))\n",
    "print(np.round(tpa3.mean(), 2), '>>', np.round(normalize_TPA(tpa3, a, b, scale).mean(), 2))\n",
    "print(\"Deviation:\")\n",
    "print(np.round(tpa1.std(), 2), '>>', np.round(normalize_TPA(tpa1, a, b, scale).std(), 2))\n",
    "print(np.round(tpa2.std(), 2), '>>', np.round(normalize_TPA(tpa2, a, b, scale).std(), 2))\n",
    "print(np.round(tpa3.std(), 2), '>>', np.round(normalize_TPA(tpa3, a, b, scale).std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It will be probably safer to perform standarization. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "29.77 >> 0.02\n",
      "29.77 >> 0.04\n",
      "29.8 >> 0.2\n",
      "Deviation:\n",
      "0.19 >> 1.05\n",
      "0.16 >> 0.89\n",
      "0.18 >> 0.97\n"
     ]
    }
   ],
   "source": [
    "def get_TPA_mean_and_std(sample_list):\n",
    "    data = read_tpa123_from_npz(sample_list[0], dtype=np.float16)[0][0][0][0][0]\n",
    "    for sample in sample_list:\n",
    "        tpa1, tpa2, tpa3 = read_tpa123_from_npz(sample, dtype=np.float16)\n",
    "        tpas = np.concatenate([tpa1, tpa2, tpa3]).flatten()\n",
    "        data = np.append(data, tpas)\n",
    "    data = data.astype(np.float32)\n",
    "    return data.mean(), data.std()\n",
    "\n",
    "def standarize_TPA(array, mean, std):\n",
    "    return (array - mean) / std\n",
    "\n",
    "TPA_mean, TPA_std = get_TPA_mean_and_std(pos_samples + neg_samples)\n",
    "\n",
    "print(\"Mean:\")\n",
    "print(np.round(tpa1.mean(), 2), '>>', np.round(standarize_TPA(tpa1, TPA_mean, TPA_std).mean(), 2))\n",
    "print(np.round(tpa2.mean(), 2), '>>', np.round(standarize_TPA(tpa2, TPA_mean, TPA_std).mean(), 2))\n",
    "print(np.round(tpa3.mean(), 2), '>>', np.round(standarize_TPA(tpa3, TPA_mean, TPA_std).mean(), 2))\n",
    "print(\"Deviation:\")\n",
    "print(np.round(tpa1.std(), 2), '>>', np.round(standarize_TPA(tpa1, TPA_mean, TPA_std).std(), 2))\n",
    "print(np.round(tpa2.std(), 2), '>>', np.round(standarize_TPA(tpa2, TPA_mean, TPA_std).std(), 2))\n",
    "print(np.round(tpa3.std(), 2), '>>', np.round(standarize_TPA(tpa3, TPA_mean, TPA_std).std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to perform normalization on RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_RGB(rgb_sequence):\n",
    "    return (rgb_sequence - rgb_sequence.mean()) / rgb_sequence.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      "125.59 >> -0.0\n",
      "Deviation:\n",
      "66.21 >> 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean:\")\n",
    "print(np.round(rgb.mean(), 2), '>>', np.round(standarize_RGB(rgb).mean(), 2))\n",
    "print(\"Deviation:\")\n",
    "print(np.round(rgb.std(), 2), '>>', np.round(standarize_RGB(rgb).std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the number of computations performed we probably want to perform these on RGB sequence resized to desired input shape (we assume that it's cropped to center when converting raw >> intermediate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to move from 02_intermediate to 03_processed that will be ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting mean and std of TPA samples...\n",
      "TPA mean: 29.76 \n",
      "TPA std: 0.18\n",
      "Processing and saving 28 samples...\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1547_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/1/20200508_1547_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1552_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/1/20200508_1552_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1553_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/1/20200508_1553_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1556_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/1/20200508_1556_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/1/20200508_1554_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/1/20200508_1554_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1525_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/1/20200508_1525_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1527_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/1/20200508_1527_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1521_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/1/20200508_1521_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1523_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/1/20200508_1523_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/1/20200508_1522_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/1/20200508_1522_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch7_20200508_1557_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch7_20200508_1557_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch5_20200508_1557_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch5_20200508_1557_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch8_20200508_1557_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch8_20200508_1557_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch3_20200508_1557_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch3_20200508_1557_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch4_20200508_1557_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch4_20200508_1557_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch2_20200508_1557_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch2_20200508_1557_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch1_20200508_1557_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch1_20200508_1557_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch6_20200508_1557_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch6_20200508_1557_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject2/0/patch0_20200508_1557_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch0_20200508_1557_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch4_20200508_1529_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch4_20200508_1529_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch3_20200508_1529_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch3_20200508_1529_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch1_20200508_1529_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch1_20200508_1529_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch6_20200508_1529_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch6_20200508_1529_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch8_20200508_1529_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch8_20200508_1529_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch0_20200508_1529_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch0_20200508_1529_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch5_20200508_1529_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch5_20200508_1529_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch2_20200508_1529_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch2_20200508_1529_.npz\n",
      "Reading /media/igor/DATA/PIPELINE/20200508_aligned_labeled_npz_f100_fs0/subject1/0/patch7_20200508_1529_.npz\n",
      "Writing ../../data/03_processed/20200508_aligned_labeled_npz_f100_fs0/development/0/patch7_20200508_1529_.npz\n",
      "Processed and saved 28 samples.\n"
     ]
    }
   ],
   "source": [
    "### BATCH MAKER START ###\n",
    "# 1. Inputs\n",
    "development_subjects =  [\"subject1\", \"subject2\"]\n",
    "pos_fp_list, neg_fp_list = get_pos_neg_fp_lists(DATASET_NAME)\n",
    "_, name = os.path.split(DATASET_NAME)\n",
    "batch_maker_dest = os.path.join(DEST, name, \"development\")\n",
    "ensure_path_exists(batch_maker_dest)\n",
    "# 2. Leave only samples from the development subjects list!\n",
    "pos_fp_list = filter_subjects_from_fp_list(pos_fp_list, development_subjects)\n",
    "neg_fp_list = filter_subjects_from_fp_list(neg_fp_list, development_subjects)\n",
    "# 3. Load in npz\n",
    "pos_samples = samples_from_fp_list(pos_fp_list)\n",
    "neg_samples = samples_from_fp_list(neg_fp_list)\n",
    "# 4. Get mean and std for TPA normalization, RGB will be normalized per sequence.\n",
    "print_if_verbose('Getting mean and std of TPA samples...')\n",
    "TPA_mean, TPA_std = get_TPA_mean_and_std(pos_samples + neg_samples)\n",
    "print_if_verbose('TPA mean: {:.2f} \\nTPA std: {:.2f}'.format(TPA_mean, TPA_std))\n",
    "# 5. Main loop\n",
    "print_if_verbose('Processing and saving {} samples...'.format(len(pos_fp_list + neg_fp_list)))\n",
    "for fp in pos_fp_list + neg_fp_list:\n",
    "    print_if_verbose(\"Reading {}\".format(fp))\n",
    "    sample = np.load(fp)\n",
    "    head, tail = os.path.split(fp)\n",
    "    tpa1, tpa2, tpa3 = read_tpa123_from_npz(sample)\n",
    "    rgb = standarize_RGB(read_rgb_from_npz(sample))\n",
    "    #5A. TPA standarization according to pt. 4\n",
    "    tpa1, tpa2, tpa3 = [standarize_TPA(t, TPA_mean, TPA_std) for t in [tpa1, tpa2, tpa3]]\n",
    "    sample_keys = list(sample.keys())\n",
    "    dict2save = {'array_ID121' : tpa1, 'array_ID122': tpa2, 'array_ID123' : tpa3, 'array_IDRGB' : rgb}\n",
    "    for key in sample_keys: \n",
    "        if key not in dict2save.keys():\n",
    "            dict2save[key] = sample[key]\n",
    "    output = os.path.join(batch_maker_dest, str(int(np.argmax(sample['one_hot']))), tail)\n",
    "    ensure_parent_exists(output)\n",
    "    print_if_verbose(\"Writing {}\".format(output))\n",
    "    np.savez_compressed(output, dict2save)\n",
    "print_if_verbose('Processed and saved {} samples.'.format(len(pos_fp_list + neg_fp_list)))\n",
    "### BATCH MAKER END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_neg_fp_lists(dataset_name):\n",
    "    pos_fp_list = glob.glob(os.path.join(\"..\",  \"..\",  \"data\", \"02_intermediate\", dataset_name, \"*\", \"1\", \"*.npz\"))\n",
    "    neg_fp_list = glob.glob(os.path.join(\"..\", \"..\",  \"data\", \"02_intermediate\", dataset_name, \"*\", \"0\", \"*.npz\"))\n",
    "    return pos_fp_list, neg_fp_list\n",
    "\n",
    "def samples_from_fp_list(fp_list):\n",
    "    return [np.load(f) for f in fp_list]\n",
    "\n",
    "def read_tpa123_from_npz(npz_sample, dtype=np.float32):\n",
    "    ids = ('121', '122', '123')\n",
    "    return [np.expand_dims(npz_sample['array_ID{}'.format(id)],axis=-1).astype(dtype) for id in ids]\n",
    "\n",
    "def read_rgb_from_npz(npz_sample):\n",
    "    return npz_sample['array_IDRGB']\n",
    "\n",
    "a = 1e-1\n",
    "b = 30\n",
    "\n",
    "def normalize_TPA(array, a, b, scale=1):\n",
    "    return scale*np.tanh(a*(array-b))\n",
    "\n",
    "def standarize_RGB(rgb_sequence):\n",
    "    return (rgb_sequence - rgb_sequence.mean()) / rgb_sequence.std()\n",
    "\n",
    "def _split_path_into_components(fp):\n",
    "    path = os.path.normpath(fp)\n",
    "    return path.split(os.sep)\n",
    "\n",
    "def filter_subjects_from_fp_list(fp_list, target_subjects):\n",
    "    result = []\n",
    "    for fp in fp_list:\n",
    "        fp_s = _split_path_into_components(fp)\n",
    "        subj_in = []\n",
    "        for subj in target_subjects:\n",
    "            if subj in fp_s:\n",
    "                subj_in.append(True)\n",
    "            else:\n",
    "                subj_in.append(False)\n",
    "        if any(subj_in):\n",
    "            result.append(fp)\n",
    "    return result\n",
    "\n",
    "def print_if_verbose(msg):\n",
    "    if VERBOSE:\n",
    "        print(msg)\n",
    "        \n",
    "def ensure_path_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def ensure_parent_exists(path):\n",
    "    ensure_path_exists(os.path.dirname(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
